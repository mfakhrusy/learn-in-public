
Almost all RL algo involve estimating value functions (functions of states or of state-action pairs) that estimate how good it is for the agent to be in a given state.

"how good" -> defined in terms of future rewards (or to be precise, expected return).

Formally, a policy is a mapping from states to probabilities of selecting each possible action. $\pi(a|s)$ is a probability that $A_t = a$ if $S_t = s$.   