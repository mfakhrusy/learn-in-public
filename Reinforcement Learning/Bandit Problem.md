> The first chapter of this part of the book describes solution methods for the special case of the reinforcement learning problem in which there is only a single state, called bandit problems. The second chapter describes the general problem formulation that we treat throughout the rest of the book—finite Markov decision processes—and its main ideas including Bellman equations and value functions

From Sutton book, Part I: Tabular solution Methods

> One of the distinguishing features of all bandit problems studied in this book is that **the learner never needs to plan for the future**. More precisely, we will invariably make the assumption that the learner's available choices and rewards tomorrow are not affected by their decisions today. **Problems that do require this kind of long-term planning fall into the realm of reinforcement learning**

from section 1.1.2 of the book Bandit Algorithms (2020)